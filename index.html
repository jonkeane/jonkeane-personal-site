<!DOCTYPE html>

<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->
<head>

<!-- Basic Page Needs
================================================== -->
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Jonathan Keane - Linguist</title>
<meta name="description" content="Jonathan Keane's Professional Website" />
<meta name="author" content="Jonathan Keane" />
<meta name="keywords" content="graduate student, research, teaching, linguistics, ASL, American Sign Language, fingerspelling, phonetics, computational, syntax, morphology" />
<meta name="description" content="PhD student of Linguistics at the University of Chicago. Research interests include articulatory phonetics, syntax, morphology, and computational approaches, sign language phonetics and phonology, and scrambling cross linguistically. " />
<meta name="robots" content="index, follow, noarchive" />
<meta name="googlebot" content="noarchive" />

<!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->

<!-- Mobile Specific Metas
================================================== -->
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<!-- CSS
================================================== -->
<link rel="stylesheet" href="stylesheets/base.css" />
<link rel="stylesheet" href="stylesheets/skeleton.css" />
<link rel="stylesheet" href="stylesheets/layout.css" />
<link rel="stylesheet" href="stylesheets/jk.css" />

<!-- Favicons
================================================== -->
<link rel="shortcut icon" href="images/favicon.ico" />
<link rel="apple-touch-icon" href="images/apple-touch-icon.png" />
<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png" />
<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png" />

<!-- Google Analytics
================================================== -->
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-27797895-1']);
  _gaq.push(['_setDomainName', '.jonkeane.com']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
</head>
<body>

<!-- Primary Page Layout
================================================== -->

<div class="container">
<div class="three columns sidebar">
  <nav>
  <img id="jon" alt="Picture of Jonathan Keane" src="images/jon.jpg" />
  <ul id="mainnav">
    <li><a href="#">Introduction</a></li>
    <li><a href="#research">Research</a></li>
    <li><a href="#software">Software</a></li>
    <li><a href="#hardware">Hardware</a></li>
  </ul>

  <ul id="external">
    <li><a href="http://pubs.jonkeane.com">publications</a></li>
    <li><a href="http://cv.jonkeane.com">cv</a></li>
    <li><a href="http://blog.jonkeane.com">blog</a></li>
    <li><a href="mailto:jonkeane@uchicago.edu">email</a></li>
  </ul>
  </nav>
  <br/>
</div>
<div class="twelve columns offset-by-one">
  <header>
  <!-- <img id="mark" src="images/jk.png" /> -->
  <h1 class="remove-bottom">Jonathan Keane</h1>
 </header>
  <hr class="large" />
<div class="doc-section clearfix" id="intro">
  <!-- <h2>Introduction</h2> -->
  <p>I am a postdoctoral scholar at the <a href="http://gslcenter.uchicago.edu/">Center for Sign, Gesture, and Language</a> at the <a href="http://uchicago.edu">University of Chicago</a>. Previously, I worked as a research assistant in the <a href="http://signlanguagelab.uchicago.edu">Sign Language Linguistics Lab</a> as well as the <a href="http://clml.uchicago.edu">Chicago Language Modeling Lab</a>. I have many research interests, particularly articulatory phonetics and phonology, morphology, and computational approaches to each. I am currently working on projects involving sign language phonetics and phonology, how perception and action influence gesture, and how gesture and sign languages interact.</p>

<p>Broadly speaking, I'm interested in how humans use their bodies to communicate both linguistically and non-linguistically. My primary focus is on how signers (people who use sign languages) use their body, arms, and hands in linguistic systems. How are the infinite number of possible configurations for a given articulator divided into meaningful groups (<em>ie</em> phonological units)? How much variation is allowed within these groups? What are the factors that contribute to this variation?</p>
  
 <p>Since the fall of 2009, I've been working with a research group consisting of researchers who specialize in linguistics, speech and language processing, and computer vision, with the goal of developing automated sign language recognition tools. This collaboration fostered my interest in the phonetics of sign languages. I hope to continue to develop models and tools that contribute both to our knowledge of phonetics generally, and inform automatic recognizers of fingerspelling.</p>
</div>
<hr />

<div class="doc-section clearfix" id="research">
  <h2>Research</h2>

  <p> For a current list of my publications please see <a href="http://pubs.jonkeane.com">my publications</a>.</p>

        <h3>American Sign Language (<span style="font-variant: small-caps;">asl</span>) fingerspelling</h3>

  <p>Fingerspelling is used anywhere from 12 to 35
	percent of the time in <span style="font-variant:
	small-caps;">asl</span>, (<a class="cite"
	href="http://scholar.google.com/scholar?q=%22How+the+alphabet+came+to+be+used+in+a+sign+language%22"
	title="C. Padden and D. Gunsauls. How the alphabet came to be used in a sign language. Sign Language Studies, 4:10–33, 2003.">Padden and Gunsauls, 2003</a>) and as such should not
	be set aside as extralinguistic. There has only been a small amount of information put together on the phonetics of fingerspelling. The only work on fingerspelling phonetics explicitly that I've found is (<a class="cite" href="http://scholar.google.com/scholar?q=%22The+phonetics+of+fingerspelling%22" title="S. Wilcox. The phonetics of fingerspelling. John Benjamins Publishing Company, 1992.">Wilcox 1992</a>) as well as (<a class="cite" href="http://scholar.google.com/scholar?q=%22Interarticulator+co-ordination+in+deaf+signers+with+parkinson’s+disease%22" title="M. Tyrone, J. Kegl, and H. Poizner. Interarticulator co-ordination in deaf signers with parkinson’s disease. Neuropsychologia, 37(11):1271–1283, 1999.">Tyrone et al. 1999</a>).</p>

  <p>I'm especially interested in how contextual variation can be modeled based on linguistic (<em>eg</em> articulator activation, phonological features) as well as non-linguistic (<em>eg</em> physiological) factors. To test theories of this variation (as well as others about phonetics, phonology, and their interface), I study how signers produce <span style="font-variant: small-caps;">asl</span> fingerspelling. Studying fingerspelling provides opportunities to find contextual and time-conditioned variation in handshape that are relatively limited in signing. This work builds on phonological systems of sign language production, but with a detailed focus on the specific aspects that make up handshapes in <span style="font-variant: small-caps;">asl</span>.</p>
  

  
  <p>My current work continues to explore fingerspelling production. I am continuing to model handshape and temporal variation that was the focus of my dissertation. I'm also involved in projects that look at how native signers as well as second language learners perceive and comprehend fingerspelling, and especially what factors contribute to successful fingerspelling comprehension; in projects that look at how handshape similarity can be quantified and tested.</p>
  
  <p>I use a variety of methods including annotated video data and instrumented capture to generate large, robust, quantitative sets of data. Similar methods have a (relatively) long tradition in spoken language linguistics, however they are only beginning to be used to look at signed languages. My work is supported in part by <span style="font-variant: small-caps;">nsf bcs</span> 1251807.</p>

  <h4>Dissertation project</h4>
  
  <p><a href="http://pubs.jonkeane.com/papers/Keane2014ad.html">My dissertation (defended August, 2014)</a> develops an articulatory phonology model (for more information, see the more detailed description <a href="#amohs">below</a>) linking the phonology and phonetics of handshapes in American Sign Language (<span style="font-variant: small-caps;">asl</span>), which was validated against data on handshape variation. On top of handshape variation, my dissertation includes detailed analyses of temporal information of the fingerspelling of native <span style="font-variant: small-caps;">asl</span> signers.</p>

<h3>Sign, Gesture, and Language</h3>

<p>I have been involved with projects with the <a href="http://gslcenter.uchicago.edu/">Center for Sign, Gesture, and Language</a> at the University of Chicago since its founding. I am currently involved with a few projects with other researchers that test the interface of gesture, action, perception, and sign languages.</p>
</div>
<hr />

<div  class="doc-section clearfix" id="software">
  <h2>Software</h2>
  
  <p>Some interesting, and hopefully helpful tools for others.</p>

   <h3>Pyelan</h3>
  
  <p>I've developed <a href="https://github.com/jonkeane/pyelan">pyelan</a>, a python module that allows for eas[y | ier] extraction and manipulation of annotation data from <a href="http://www.lat-mpi.eu/tools/elan/">elan</a> files. Although this is a work in progress, some core functionality has been implemented. Pyelan can read, write, and preform some manipulations of eaf files. Pyelan now also allows for linking csv files to be viewed in the timeseries viewer. Please feel free to use, fork, submit issues, and submit pull requests.</p>

   <h3>PhaseSpaceHelper for PhaseSpace motion capture systems</h3>
 
  <p><a href="https://github.com/jonkeane/PhaseSpaceHelper">PhaseSpaceHelper</a> is a python module that contains some convenience functions to deal with synchronizing stimulus presentation and data collection (through <span style="font-variant: small-caps;">smpte</span> timecode), as well as verifying the accuracy of calibration given a set object. Warning: this is very much in active development right now.</p>
  
  <h3 id="amohs">The Articulatory Model of Handshape</h3>
  <p>For my dissertation, I implemented a computational model of the phonetics-phonology interface, that I call the Articulatory Model of Handshape. The implementation is as the <a href="https://github.com/jonkeane/amohs">amohs</a> python module. This module not only implements automatic translation from phonological features to various types of phonetic representations (including joint angle targets), but it also uses an external library to render <span style="font-variant: small-caps;">3d</span> images of hands.</p>
  
  <p>The Articulatory Model of Handshape uses a slightly modified version of <a class="cite" href="https://scholar.google.com/scholar?q=%22A+Prosodic+Model+of+Sign+Language+Phonology%22" title="D. Brentari. A Prosodic Model of Sign Language Phonology. The MIT Press, 1998.">Brentari's 1998</a> Prosodic Model of handshape for a phonological representation of handshape. It than provides representations for phonetic specifications either as tract variables (at a categorical level), and as phonetic joint angle targets (a continuous level) for handshapes. Using these representations, comparisons between handshapes can be made deriving a theory-driven metric of handshape similarity.</p>
  
  <p>On top of the computational implementation described above, the module uses an external library, <a href="http://www.libhand.org/">LibHand</a> to render images of synthesized handshapes. Currently, the model only renders isolated handshapes, but in the future could be extended to sequences of handshapes (including transitions), that is, video of handshapes moving over time. Because they are based on representations that can be linked to multiple levels of phonetics and phonology, these videos could include information about coarticulation (contextual dependencies) of the kind that was demonstrated in my dissertation.</p>
  
  <p>At the time that I was trying, <a href="http://www.libhand.org/">LibHand</a> failed to compile on modern versions of OS X. I have setup <a href="https://github.com/jonkeane/libhand">a repository</a> that includes the changes needed to compile LibHand on OS X 10.9 Mavericks. Compiling via <a href="http://brew.sh/">homebrew</a> is possible, with some <a href="https://github.com/jonkeane/homebrew-libhand">alterations</a> to ogre as well.</p>
  
  <h3>SLGloss LaTeX package</h3>
  
  <p>In collaboration with <a href="https://files.nyu.edu/ik747/public/">Itamar Kastner</a>, I've helped developed <a href="https://github.com/itamarkast/slgloss">the SLGloss LaTeX package</a> to make it easier to typeset sign language glosses. It has three main features:   </p>
<ol>
  <li> It typesets sign glosses in smallcaps to integrate typographically with surrounding text, as well as allows for non-manual markings over specific constituents.</li>
  <li> It typesets fingerspelled words in small caps with hyphens between the letters</li>
  <li>It typesets lists of individual fingerspelled letters with hyphens on either side.</li>
  </ol>

   <h3>Fflipper</h3>
  
  <p>I've developed <a href="https://github.com/jonkeane/fflipper">fflipper</a>, a python module that allows for extraction of clipped videos based on the annotations extracted from an <a href="http://www.lat-mpi.eu/tools/elan/">elan</a> file.</p>

<h3><span style="font-variant: small-caps;">asl</span> fingerspelling chart</h3>

<img src="images/Asl_alphabet_gallaudet.jpg" alt="Chart of ASL fingerspelling handshapes" />

<p>After seeing many charts that were licensed and reproduced with permission, I decided to recreate a fingerspelling chart and release it using a very liberal content license so researchers and educators that need this chart can use it (nearly) freely. The handshapes are based on the font from David Rakowski.</p>

<p>There a few problems with this chart. The biggest problem is that the orientation of many letters is altered to show the configuration of the fingers. In reality, all of the handshapes are made with the palming facing out, away from the signer with the exception of <span style="font-variant: small-caps;">-g-</span> (in, towards the signer), <span style="font-variant: small-caps;">-h-</span> (in, towards the signer), <span style="font-variant: small-caps;">-p-</span> (down), <span style="font-variant: small-caps;">-q-</span> (down) and the end of <span style="font-variant: small-caps;">-j-</span> (to the side)</p>

<p>Download the <a href="Asl_alphabet_gallaudet.pdf">full sized, completely vector-based PDF version</a>.</p>
	
<a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-sa/3.0/88x31.png" /></a><p>This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>


<h3>Better type for LaTeX</h3>

<p>In the pursuit of better typography for LaTeX I've found a couple of good walkthroughs, and a couple of invaluable tools. All of the following have been tested on TeX Live 2009, 2010, and 2011 on both OS X 10.5, 10.6, and 10.7. </p>
	
<h4>Minion Pro</h4>
<p>I've created <a href="http://github.com/jonkeane/MinionProforLaTeX">a bash script</a> that installs Minion Pro to a local TeX Live tree with very little user intervention.
</p>

<h4>otfinst.py</h4>
<p>
John Owens has developed <a href="http://www.ece.ucdavis.edu/~jowens/code/otfinst/">a great python tool</a> that installs many OpenType fonts. The only stumbling block I found besides some font incompatibilities was assigning (making up) <a href="http://www.tex.ac.uk/tex-archive/info/fontname/fontname.pdf">Berry names</a> to the fonts that I wanted to install, which have to be added to the script. I have made up names for the following that seem to adhere most of the conventions. If anyone knows of more widespread names for these typefaces, please <a href="mailto:jonkeane@uchicago.edu">let me know</a>.
</p>

<ul>
  <li>'Neutraface Text' : 'fne'</li>
  <li>'Neutraface Display' : 'fn3'</li>
  <li>'Gotham' : 'fg7'</li>
  <li>'Gotham Rounded' : 'fg8'</li>
</ul>
</div>

<hr />
<div  class="doc-section clearfix" id="hardware">
  <h2>Hardware</h2>

  <p>I dabble in hardware development (really, mostly hacking existing products to do things I find useful).</p>

  <h3>Button board</h3>

  <p>Through the process of collecting various kinds of psycholinguistic data, I found the need to have a versatile, inexpensive feedback system for participants to use in order to interact with a computer during the course of an experiment. Although button boxes exist already, they are typically very expensive, and not of the form factor we desired for use in experiments.</p>
  
  <p>To solve this, I developed <a href="https://github.com/jonkeane/buttonBoard">a button board </a> based on a <a href="http://www.pjrc.com/teensy/">Teensy 2.0</a> microcontroler and a in conjunction with momentary switch (e.g. <a href="http://www.infogrip.com/products/switches/specs-switch.html">Infogrip's Specs Switch</a>). The microcontroller is flexible enough to provide the computer with virtually any type of <span style="font-variant: small-caps;">usb</span> input possible when one of up to 4 buttons are pressed.</p>
  
  <h3>Kindle weather and <span style="font-variant: small-caps;">cta </span> arrival times display</h3>

  <p>After seeing <a href="http://mpetroff.net/2012/09/kindle-weather-display/">a number </a><a href="https://github.com/pjimenezmateo/kindle-wallpaper">of people</a> <a href="http://hackaday.com/2013/04/01/kindle-weather-and-recycling-display/">make</a> <a href="http://www.shatteredhaven.com/2012/11/1347365-kindle-weather-display.html">various</a> persistent display devices with kindles, I decided that what I really needed was a display for weather as well as various <span style="font-variant: small-caps;">cta </span> arrival times near my apartment.</p>
  <p>I developed a <a href="https://github.com/jonkeane/kindle-weather-display">setup</a> that grabs weather from <a href="http://www.wunderground.com/weather/api/">wunderground</a> or <a href="https://developer.forecast.io/">forecast.io</a>, as well as arrival times for a limited number (5 currently, due to space restrictions of the kindle) of <span style="font-variant: small-caps;">cta </span> stops and stations. Then displays the arrivals persistently, and cycles through: current weather conditions, a 12 hour forecast, and a 5 day forecast.</p>
  <p> Not content to just tack a kindle on the wall, I built <a href="https://www.flickr.com/photos/jonkeane/sets/72157639487321246/">a wood frame</a> using a laser cutter to house the kindle and reroute the usb cable for charging.</p>
   
   <img width=100% alt="Image of the kindle weather and arrival times display, in a wood frame." src="images/kindleWeather.jpg" />
   
   
</div>
<div  class="footer clearfix" id="colophon">
  <p>(As valid as possible, given both are still evolving specifications) <a href="http://validator.w3.org/check?uri=http%3A%2F%2Fjonkeane.com">HTML5</a> and <a href="http://jigsaw.w3.org/css-validator/validator?uri=http%3A%2F%2Fjonkeane.com&amp;profile=css3&amp;usermedium=all&amp;warning=1&amp;vextwarning=true&amp;lang=en">CSS3</a>. Based on the <a href="http://www.getskeleton.com/">skeleton</a> development kit. Background image from <a href="http://subtlepatterns.com/">subtlepatterns</a>. Typeset in <a href="http://www.fontshop.com/fontlist/families/azuro/">Azuro</a>. Hosted on <a href="http://www.github.com">GitHub</a>.</p>
  
</div>

</div>

</div><!-- container -->

<!-- JS
================================================== -->
<script type="text/javascript" src="http://code.jquery.com/jquery-1.6.4.min.js" ></script>
<script type="text/javascript" src="javascripts/tabs.js"></script>

<!-- End Document
================================================== -->
</body>
</html>